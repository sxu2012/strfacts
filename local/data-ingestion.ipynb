{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Jupyter Notebook with Python 3 on Windows 11\n",
    "## Read data from local storage, Cleaning / Transforming the data, then persist data in parquet format with partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = 'c:/sb/strfacts/indata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ingestion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all csv files of last quarter, folders in format yyyy-mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.now()\n",
    "print(today.year)\n",
    "print(today.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free data is available quaterly, but you can pay to get monthly data. For now we will use free data\n",
    "# Calculate date for the last quater data.\n",
    "if today.month in [1, 2, 3]:\n",
    "    dirnames = [\"{}-{}\".format(today.year-1, i) for i in ['10','11','12']]\n",
    "elif today.month in [4, 5, 6]:\n",
    "    dirnames = [\"{}-{}\".format(today.year, i) for i in ['01','02','03']]\n",
    "elif today.month in [7, 8, 9]:\n",
    "    dirnames = [\"{}-{}\".format(today.year, i) for i in ['04','05','06']]\n",
    "else:\n",
    "    dirnames = [\"{}-{}\".format(today.year, i) for i in ['07','08','09']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define schema for reviews.csv.gz\n",
    "reviews_schema = StructType([\n",
    "    StructField('location', StringType(), True),\n",
    "    StructField('listing_id', StringType(), True),\n",
    "    #StructField('id',         IntegerType(),True),\n",
    "    StructField('date',       StringType(),True),\n",
    "    #StructField('reviewer_id', IntegerType(),True),\n",
    "    StructField('reviewer_name', StringType(),True),\n",
    "    StructField('comments', StringType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-01', '2022-02', '2022-03']\n"
     ]
    }
   ],
   "source": [
    "print (dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse csv file\n",
    "def parse_csv(line:str, location):\n",
    "    f =line.split(',')\n",
    "    if len(f) < 6:\n",
    "        # \"NONE\" partition holds the invalid data\n",
    "        #return (\"NONE\", None, None, None, None, None, None)\n",
    "        return (\"NONE\", None, None, None, None)\n",
    "    else:\n",
    "        # join the comments together into one string\n",
    "        comments = ''\n",
    "        for words in f[5:]:\n",
    "            comments = comments +' '+words\n",
    "        return(location,f[0],f[2],f[4],comments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd\n",
    "reviews_rdd = None\n",
    "for dn in os.listdir(indata):\n",
    "    # read the files in this folder if dn is last quarter\n",
    "    if dn in dirnames:\n",
    "        # for this project, we are only interested in the reviews.csv.gz file\n",
    "        filenames = os.listdir(indata+'/'+dn)\n",
    "        for fn in filenames:\n",
    "            a = len(fn)\n",
    "            b = len(\"reviews.csv.gz\")\n",
    "            # hawaii.reviews.csv.gz; location = hawaii\n",
    "            if a > b and fn[a-b:] == \"reviews.csv.gz\":\n",
    "                location = fn[:a-b-1]\n",
    "                raw_rdd=spark.sparkContext.textFile(indata+'/'+dn+'/'+fn)\n",
    "                header = raw_rdd.first() #get the first row to a variable\n",
    "                #remove the header, then clean the rest rows with parse_csv()\n",
    "                clean_rdd = raw_rdd.filter(lambda row:row != header)\\\n",
    "                                   .map(lambda row: parse_csv(row, location))\n",
    "                if reviews_rdd is None:\n",
    "                    reviews_rdd = clean_rdd\n",
    "                else:\n",
    "                    union_rdd = reviews_rdd.union(clean_rdd)\n",
    "                    reviews_rdd = union_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep a small data set in the local indata folder to make the next line a bit faster, for easy development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to the parquet files with place name as partition\n",
    "cleandata = 'c:/sb/strfacts/cleandata'\n",
    "reviews_df = spark.createDataFrame(reviews_rdd, schema=reviews_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-------------+--------------------+\n",
      "|location|listing_id|      date|reviewer_name|            comments|\n",
      "+--------+----------+----------+-------------+--------------------+\n",
      "|  hawaii|   2797791|2014-05-03|        Evita| \"We spent a week...|\n",
      "|  hawaii|   2797791|2014-05-28|      Michael| The reservation ...|\n",
      "|  hawaii|   2797791|2014-06-02|          Tim| \"It was an epic ...|\n",
      "|    NONE|      null|      null|         null|                null|\n",
      "|    NONE|      null|      null|         null|                null|\n",
      "+--------+----------+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.write.partitionBy(\"location\").mode(\"append\").parquet(cleandata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
